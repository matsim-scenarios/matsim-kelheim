---
title: "Bad weather Kelheim Demo"
author: "Oleksandr Soboliev"
output:
  html_document:
    df_print: paged
  html_notebook:
    theme: cosmo
    highlight: monochrome
    code_folding: show
runtime: shiny
editor_options:
  chunk_output_type: inline
---

```{r, include= FALSE}
library(tidyverse)
library(lubridate)
library(plotly)
library(leaflet)
library(rmarkdown)
library(modelr)
library(splines)
library(forecast)
library(fitdistrplus)
library(rjson)
library(knitr)

if ("fitdistrplus" %in% (.packages())){
  detach(package: fitdistrplus, unload = TRUE)
}

if ("fitdistrplus" %in% (.packages())){
  detach(package: MASS, unload = TRUE)
}

if ("fitdistrplus" %in% (.packages())){
  detach(package: stats, unload = TRUE)
}

knitr::opts_chunk$set(echo = TRUE)
```

## **Research Meteostat**

After some researches about meteostat data nearest station in DE that belongs to Kelheim region are:

-   "Mallersdorf-Pfaffenberg/Niederbayern" with an id: "D3147"
-   "Neumarkt / HÃ¶henberg" with and id: "69110"
-   Uebungsdorf / Emhof

there are many of them so I am starting to think about extracting all from the Bayern or extract the nearest from longtitude/latitude point with the Kelheim shapefile(using json and Euclid distances)

[Kelheim has no weather station, but it could be reconstructed with 2 other](https://weatherspark.com/y/70370/Average-Weather-in-Kelheim-Germany-Year-Round)

Hohenfels with id: "10775" and Ingolstadt with id:"10860" **kelheim_data = {weight1}x{hohenfels} + {weight2}x{inglstadt}**

Also this site shows, that there are many of the Kelheim stations in this area, but meteostat doesn't contain them <https://www.wunderground.com/dashboard/pws/IKELHE5>

## **Research Weatherstack**

```{r first look at weatherstack data specific to Kelheim}
weatherstack_kelheim = read_delim("data/Kelheim_weather_since_july_2008.csv",delim = ",")
print(weatherstack_kelheim)
```

What to take as a reffer point isn't clear because of the date(before/after covid) and weather type (sunny,clear,temperature) Also there is no temperature in it :/

## **Import mobility from Google**

```{r including google germany mobility data,message=FALSE}
#global_mobility = read_delim("https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv",",")
#de_mobility = global_mobility %>% filter(country_region_code == "DE")
```

```{r what regions are data provided}
#print(unique(de_mobility$sub_region_1))

```

As we can see the most precise region to filter data from is Bavaria :/

Relevant data for the , mobility

```{r mobility data bavaria}
#bavaria_mobility = de_mobility %>% filter(sub_region_1 == "Bavaria")
#bavaria_mobility = bavaria_mobility %>% #dplyr::select(country_region,sub_region_1,date,residential_percent_change_from_baseline) %>%
#  mutate(residential_percent_change_from_baseline = -residential_percent_change_from_baseline,
#         source = "Google")%>%
#  rename(BundeslandID = sub_region_1,not_at_home_change = residential_percent_change_from_baseline)
#bavaria_mobility = bavaria_mobility %>% dplyr::select(date,BundeslandID,not_at_home_change,source)
#Need to filter out weekends

#plt = ggplot(bavaria_mobility)+
#  geom_point(aes(x = date,y = not_at_home_change))
#ggplotly(plt)
```

## **Import mobility from Senozon**

```{r import from senozon}
snz_mobility = read_delim("data/LK_mobilityData_weekdays.csv",";")

#Kelheim
snz_mobility_kelheim = snz_mobility %>% filter(Landkreis == "Landkreis Kelheim") %>% mutate(source = "senozon") %>% dplyr::select(-outOfHomeDuration) %>% rename(not_at_home_change = percentageChangeComparedToBeforeCorona)
snz_mobility_kelheim$date = as.Date(strptime(snz_mobility_kelheim$date,"%Y%m%d"))

#Berlin
snz_mobility_berlin = snz_mobility %>% filter(Landkreis == "Berlin") %>% mutate(source = "senozon") %>% dplyr::select(-outOfHomeDuration) %>% rename(not_at_home_change = percentageChangeComparedToBeforeCorona)
snz_mobility_berlin$date = as.Date(strptime(snz_mobility_berlin$date,"%Y%m%d"))

colors <- c("Berlin" = "blue", "Kelheim" = "red")

plt = ggplot()+
  geom_point(data = snz_mobility_kelheim,aes(x = date,y = not_at_home_change,color = "Berlin"))+
  geom_point(data = snz_mobility_berlin,aes(x = date,y = not_at_home_change,color = "Kelheim"))+
  scale_colour_manual(values = colors)
ggplotly(plt)
```

## **Aggregate 2 sources**

We take berlin weather from station in Schoenefeld with id = 10384
```{r adding berlin weather, echo=FALSE}
berlin_weather_daily = read_delim("https://bulk.meteostat.net/v2/daily/10385.csv.gz",",",col_names = FALSE)
colnames(berlin_weather_daily) = c("date", "tavg", "tmin", "tmax", "prcp", "snow", "wdir", "wspd", "wpgt", "pres", "tsun")
```


```{r define weather data as week data}
# think about duration of description column
# Kelheim
weatherstack_kelheim_daily = weatherstack_kelheim %>%
  group_by(date) %>%
  summarize(description = description,precip_day = sum(precip),visibility_mean = mean(visibility),totalsnow_daily = mean(totalsnow_daily))
  
weatherstack_kelheim_weekly = weatherstack_kelheim_daily %>% 
  mutate(year_week = paste0(isoyear(date),"-",isoweek(date))) %>%
  group_by(year_week) %>%
  summarize(description = description,date = first(date), precip_week = sum(precip_day),visibility_mean = mean(visibility_mean),totalsnow_weekly =sum( totalsnow_daily))
weatherstack_kelheim_weekly = unique(weatherstack_kelheim_weekly)
print(weatherstack_kelheim_weekly)

#Berlin
  
berlin_weather_weekly = berlin_weather_daily %>% filter(year(date) >=2020) %>%
  mutate(year_week = paste0(isoyear(date),"-",isoweek(date))) %>%
  group_by(year_week) %>%
  summarize(date = first(date), prcp_week = sum(prcp), tavg= mean(tavg),snow_week =sum( snow),wspd = mean(wspd),tmax = max(tmax)) %>%
  arrange(year_week)
print(berlin_weather_weekly)
  
```

```{r google+senozon+weather}
#mob_joined = rbind(snz_mobility_kelheim,bavaria_mobility)
#Kelheim
snz_mobility_kelheim_year_week = snz_mobility_kelheim %>% 
  mutate(year_week = paste0(isoyear(date),"-",isoweek(date))) %>%
  group_by(year_week) %>%
  summarize(date = first(date),not_at_home_change = mean(not_at_home_change))
mob_joined_with_weather_kelheim = snz_mobility_kelheim_year_week %>% inner_join(weatherstack_kelheim_weekly, by = "year_week") %>% dplyr::select(-date.y) %>% rename(date = date.x)
print(mob_joined_with_weather_kelheim)

#Berlin
snz_mobility_berlin_year_week = snz_mobility_berlin %>% 
  mutate(year_week = paste0(isoyear(date),"-",isoweek(date))) %>%
  group_by(year_week) %>%
  summarize(date = first(date),not_at_home_change = mean(not_at_home_change))
mob_joined_with_weather_berlin = snz_mobility_berlin_year_week %>% inner_join(berlin_weather_weekly, by = "year_week") %>% dplyr::select(-date.y) %>% rename(date = date.x)
print(mob_joined_with_weather_berlin)
```

```{r first plot}
#First plot with colour as precipitation
shapes <- c("Berlin" = 5, "Kelheim" = 3)
plt_color = ggplot()+
  geom_point(data = mob_joined_with_weather_kelheim,aes(x = date,y = not_at_home_change,colour = precip_week,shape = "Kelheim"))+
  #geom_point(data = mob_joined_with_weather_berlin,aes(x = date,y = not_at_home_change,colour = prcp_week,shape = "Berlin"))+
  scale_color_gradient2()+
  scale_shape_manual(values = shapes)
  

ggplotly(plt_color)
```

```{r second plot}
#Second plot as another line as precipitation
plt_line = ggplot(mob_joined_with_weather_kelheim)+
  geom_point(aes(x = date,y = not_at_home_change))+
  geom_line(aes(x = date,y = precip_week*0.5,color = "red"))
  

ggplotly(plt_line)
```

```{r precipitation histogram}
plt_hist_precip = ggplot(mob_joined_with_weather_kelheim,aes(x = precip_week,y = not_at_home_change))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 2,fill = "blue")

ggplotly(plt_hist_precip)
```

```{r visibility histogram}
plt_hist_visibility = ggplot(mob_joined_with_weather_kelheim,aes(x = visibility_mean,y = not_at_home_change))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 0.5,fill = "blue")

ggplotly(plt_hist_visibility)
```

```{r totalsnow histogram}
plt_hist_totalsnow = ggplot(mob_joined_with_weather_kelheim,aes(x = totalsnow_weekly,y = not_at_home_change))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 7,fill = "blue")

ggplotly(plt_hist_totalsnow)
```

```{r looking at description column}
#this is a bad plot because it takes description of 1 day of the week
plt_hist_descr = ggplot(mob_joined_with_weather_kelheim,aes(x = description,y = not_at_home_change))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 5,fill = "blue")+
  coord_flip()

ggplotly(plt_hist_descr)
```

## Let's try it out with meteostat data, that contains scope of the 2022 without restictions

Ingolstadt data from id = 10860 station

```{r Ingolstadt data}
ingolstadt_weather = read_delim("https://bulk.meteostat.net/v2/daily/10860.csv.gz",",",col_names = FALSE)

colnames(ingolstadt_weather) = c("date", "tavg", "tmin", "tmax", "prcp", "snow", "wdir", "wspd", "wpgt", "pres", "tsun")


# We don't need data of weather before 2020, because of snz_mobility date, also data isn't precise

ingolstadt_weather = ingolstadt_weather %>% filter(year(date)>=2020)%>% replace_na(list(snow = 0))

print(ingolstadt_weather)
```

Hohenfels data from id = 10775 station

```{r Hohenfels data}
hohenfels_weather = read_delim("https://bulk.meteostat.net/v2/daily/10775.csv.gz",",",col_names = FALSE)

colnames(hohenfels_weather) = c("date", "tavg", "tmin", "tmax", "prcp", "snow", "wdir", "wspd", "wpgt", "pres", "tsun")


# We don't need data of weather before 2020, because of snz_mobility date, also data isn't precise

hohenfels_weather = hohenfels_weather %>% filter(year(date)>=2020) %>% replace_na(list(snow = 0))

print(hohenfels_weather)
```

As we can see in Hohenfels data isn't that accurate and precipitation is data is missing fr year 2020, so for the further analysis we take only Ingolstadt data.

```{r Ingolstadt weekly data}
ingolstadt_weather_weekly = ingolstadt_weather %>% 
  mutate(year_week = paste0(isoyear(date),"-",isoweek(date))) %>%
  group_by(year_week) %>%
  summarize(date = first(date), prcp_week = sum(prcp), tavg= mean(tavg),snow_week =sum( snow),wspd = mean(wspd),tmax = max(tmax)) %>%
  arrange(year_week)
#ingolstadt_weather_weekly = unique(weatherstack_kelheim_weekly)
print(ingolstadt_weather_weekly)
```

```{r aggregate snz and ingolstadt}
mob_joined_with_ingolstadt = ingolstadt_weather_weekly %>% 
  inner_join(snz_mobility_kelheim_year_week, by = "year_week") %>% 
  dplyr::select(-date.x) %>%
  rename(date = date.y) %>%
  replace_na(list(tmax = 0))

print(mob_joined_with_ingolstadt)
```

```{r colored precipitation plot Ingolstadt}
#First plot with colour as precipitation
fills <- c("Ingolstadt" = "blue", "Berlin" = "red")
plt_ing_color = ggplot(mob_joined_with_ingolstadt)+
  geom_point(aes(x = date,y = not_at_home_change,colour = prcp_week,fill = "Ingolstadt"))+
  geom_point(data = mob_joined_with_weather_berlin,aes(x = date,y = not_at_home_change,colour = prcp_week,fill = "Berlin"))+
  scale_color_gradient(low = "white",high = "black")+
  scale_fill_manual(values = fills)

ggplotly(plt_ing_color)
```


```{r precipitation as line plot}
plt_ing_color = ggplot(mob_joined_with_ingolstadt)+
  geom_point(aes(x = date,y = not_at_home_change))+
  geom_line(aes(x = date,y = prcp_week,color = "Ingolstadt"))+
  #geom_line(data = berlin_weather_weekly,aes(x = date,y = prcp_week,color = "Berlin"))+
  scale_color_manual(values = fills)+
  ggtitle("Kelheim mobility with precipitation as line plot on same axis")

ggplotly(plt_ing_color)
```

```{r join ingolstadt and berlin in 1 table}
# replace coluumn positioning

mob_joined_with_weather_berlin = mob_joined_with_weather_berlin %>% dplyr::select(year_week,prcp_week,tavg,snow_week,wspd,tmax,date,not_at_home_change)

mob_joined_with_weather_berlin = mob_joined_with_weather_berlin %>% mutate(landkreis = "Berlin")

mob_joined_with_ingolstadt = mob_joined_with_ingolstadt %>% mutate(landkreis = "Ingolstadt")

mob_joined_with_ing_berlin = rbind(mob_joined_with_ingolstadt,mob_joined_with_weather_berlin)
```

```{r histogram with precip}
plt_hist_precip_ing = ggplot(mob_joined_with_ing_berlin,aes(x = prcp_week,y = not_at_home_change,fill = landkreis))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 2,position =  position_dodge())

ggplotly(plt_hist_precip_ing)

```

```{r histogram with average temperature}
plt_hist_precip_ing = ggplot(mob_joined_with_ing_berlin,aes(x = tavg,y = not_at_home_change,fill = landkreis))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 2,position = position_dodge2())

ggplotly(plt_hist_precip_ing)

```

```{r histogram with maximal temperature}
plt_hist_precip_ing = ggplot(mob_joined_with_ing_berlin,aes(x = tmax,y = not_at_home_change,fill = landkreis))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 2)

ggplotly(plt_hist_precip_ing)

```

```{r histogram with snow at the week}
plt_hist_precip_ing = ggplot(mob_joined_with_ing_berlin,aes(x = snow_week,y = not_at_home_change,fill = landkreis))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 50)

ggplotly(plt_hist_precip_ing)

```

After first look at data, we can assume that hours out of home strongly depend on average temperature outside, that sounds logical. Mb categorization seasons of the data will help to understand this function

```{r adding new season column}
mob_joined_with_ing_berlin = mob_joined_with_ing_berlin %>% 
  mutate(season = ifelse(month(date) %in% c(12,1,2),"winter",NA)) %>%
  mutate(season = ifelse(month(date) %in% c(3,4,5),"spring",season)) %>%
  mutate(season = ifelse(month(date) %in% c(6,7,8),"summer",season)) %>%
  mutate(season = ifelse(month(date) %in% c(9,10,11),"autumn",season))
```


```{r season ~ not_at_home:  plots}
#insert also a data about overall in germany
plt_hist_season = ggplot(mob_joined_with_ing_berlin,aes(x = season,y = not_at_home_change,fill = landkreis))+
  stat_summary_bin(fun = "mean",
                   geom = "bar",
                   binwidth = 5,position = position_dodge())

ggplotly(plt_hist_season)
```


So it seems that season has an enormous impact at mobility of citizens.
Another important parameter can be description of the weather based on Kelheim statistics, we will merge it into Ingolstadt weather, because of the assumption, that Ingolstadt ad Kelheim have the similar weather properties.

```{r adding description to an ingolstadt data}
type_of_weather = unique(weatherstack_kelheim$description)

weatherstack_kelheim_year_week = weatherstack_kelheim %>% mutate(year_week = paste0(isoyear(date),"-",isoweek(date)))

week_description_impact = weatherstack_kelheim_year_week %>% group_by(year_week) %>% count(description)

week_description_impact = week_description_impact %>% pivot_wider(names_from = description,values_from = n)

#remove NAs
week_description_impact[is.na(week_description_impact)] = 0
print(week_description_impact)
```
```{r join it with mobility data Ingolstadt}
mob_joined_with_ingolstadt_description = mob_joined_with_ingolstadt %>% inner_join(week_description_impact, by = "year_week")
#normalize it to a percentage
#mob_joined_with_ingolstadt_description[type_of_weather] = mob_joined_with_ingolstadt_description[type_of_weather]/168 #168 hours a week

#Assumption not_at_home_change is calculated through individual weather impact normally
#=> each type of weather for the weak get its own weather impact based on not_at_home

#mob_joined_with_ingolstadt_description[type_of_weather] = mob_joined_with_ingolstadt_description[type_of_weather]*mob_joined_with_ingolstadt_description$not_at_home_change


print(mob_joined_with_ingolstadt_description)
```


```{r lets barchart it :)}
mob_joined_with_ingolstadt_description_longer = mob_joined_with_ingolstadt_description%>% pivot_longer(cols = all_of(type_of_weather),names_to = "description",values_to = "value")# %>% filter(value!=0)

description_impact_overall = mob_joined_with_ingolstadt_description_longer %>% 
  filter(value!=0) %>% #mutate(value = value*not_at_home_change)%>% mutate(value = ifelse(value>0,value*not_at_home_change,-value*not_at_home_change)) %>%
  group_by(description) %>% summarize(impact = mean(not_at_home_change))

plot_ly(data = description_impact_overall,x = ~description,y = ~impact,type= "bar")
```

Another approach

```{r}
map_vector <- c("Clear","Sunny","Cloudy","Light","Light","Light","Light","Light","Light","Light","Light","Medium","Cloudy","Light","Light","Heavy","Heavy","Heavy","Light","Medium","Heavy","Heavy","Light","Heavy","Heavy","Heavy","Heavy","Heavy","Heavy","Light","Medium","Medium","Light","Heavy","Light","Light","Light","Light","Light","Heavy","Light","Medium","Heavy","Heavy","Heavy")
names(map_vector)<- type_of_weather
mob_joined_with_ingolstadt_description_longer_mapped = mob_joined_with_ingolstadt_description_longer
mob_joined_with_ingolstadt_description_longer_mapped$description = map_vector[(mob_joined_with_ingolstadt_description_longer_mapped$description)]

description_impact_max = mob_joined_with_ingolstadt_description_longer_mapped %>% group_by(year_week)%>%
  top_n(1,value) %>% group_by(description) %>% summarize(impact = mean(not_at_home_change))

description_impact = mob_joined_with_ingolstadt_description_longer_mapped %>% group_by(year_week)%>%
  top_n(1,value)

week_calender = as.Date(seq(ISOdate(2014,1,3),ISOdate(2022,12,1),by="week"))
week_calender = data.frame(date = week_calender)
week_calender = week_calender %>% mutate(year_week = paste0(year(date),"-",isoweek(date)))

mob_joined_with_ingolstadt_description_longer_mapped = mob_joined_with_ingolstadt_description_longer_mapped %>% 
  inner_join(week_calender,by = "year_week")



plot_ly(data = description_impact_max,x = ~description,y = ~impact,type= "bar")

print(description_impact_max)

```

## **Add stringency of covid policies to a data**
```{r import}
json = fromJSON(file = "data/2022-10-08.json")
unlisted_json = unlist(json)
```

```{r}
deu_stringency = unlisted_json[grep("DEU.stringency_actual",names(unlisted_json))]
date_stringency = sapply(strsplit(names(deu_stringency),split = ".",fixed = TRUE),"[[",2)
df_stringency = data.frame(date = date_stringency,stringency = deu_stringency)
df_stringency = df_stringency %>% mutate(year_week = paste0(year(date),"-",isoweek(date)),stringency = as.numeric(stringency))%>%ungroup() %>% group_by(year_week) %>% summarize(stringency = mean(stringency))
```

## **Insert new data from kexi region**


```{r message=FALSE}
demandDRT = read_delim("data/allDemandByDate.csv")
```



## **Take a policy data into table**
## **Statisctical evaluation of null hypothesis, independency tests**
## **Starting with a model**



After first data preparation and analysis, let's try to make some predicitions about not_at_home duration based on plots that shown us a major impact on not_at_home variable, like *tavg*, *season*, *description*, *tavg*. Starting with a *linear model* and using *Ingolstadt data* limited by year 2020,2021

```{r add a season}
description_impact = description_impact %>% 
  mutate(season = ifelse(month(date) %in% c(12,1,2),"winter",NA)) %>%
  mutate(season = ifelse(month(date) %in% c(3,4,5),"spring",season)) %>%
  mutate(season = ifelse(month(date) %in% c(6,7,8),"summer",season)) %>%
  mutate(season = ifelse(month(date) %in% c(9,10,11),"autumn",season))
description_impact = description_impact %>% inner_join(df_stringency, by = "year_week")

```

## **Import holidays**
```{r}
help_function <- function(list1,list2){
  
}
```


```{r}
holidays2020 = read_csv2("data/Holidays2020.csv") %>% dplyr::select(1,2,3)
holidays2021 = read_csv2("data/Holidays2021.csv") %>% dplyr::select(1,2,3)
holidays2022 = read_csv2("data/Holidays2022.csv") %>% dplyr::select(1,2,3)
holidays = rbind(holidays2020,holidays2021,holidays2022)
holidays = holidays %>% mutate(EndDateTime1 = as.Date(mdy_hm(EndDateTime1)),
                               StartDateTime1 = as.Date(mdy_hm(StartDateTime1)))

holiday_days = c(seq(holidays$StartDateTime1[1],holidays$EndDateTime1[1],by = "days"))

for(i in 1:nrow(holidays)){
  holiday_days = append(holiday_days,seq(holidays$StartDateTime1[i],holidays$EndDateTime1[i],by = "days"))
}

df_holidays = data.frame(date = holiday_days,isHoliday = TRUE)

week_calender = data.frame(date = as.Date(seq(ISOdate(2020,1,1),ISOdate(2022,12,31),by = "days")))
week_calender = week_calender %>% mutate(year_week = paste0(year(date),"-",isoweek(date)))

train_data = description_impact %>% left_join(df_holidays, by ="date") %>% replace_na(list(isHoliday = FALSE))

```

```{r}
demandDRT_week = demandDRT %>% mutate(year_week = paste0(year(date),"-",week(date)))%>% ungroup() %>% group_by(year_week) %>% summarize(noRides = sum(noRides),noRequests = sum(noRequests),avgEuclidianDistance_m = mean(avgEuclidianDistance_m), avgTravelTime_s = mean(avgTravelTime_s))
demand_table = demandDRT_week %>% inner_join(description_impact,by = "year_week")

best_pred <- demand_table %>% ungroup() %>%
  dplyr::select(-noRides,-landkreis,-description ,-year_week,-date,-value,-season,-noRequests,-avgEuclidianDistance_m,-not_at_home_change,-avgTravelTime_s) %>%
  map_dbl(cor,y = demand_table$noRides) %>%
  #map_dbl(abs) %>%
  sort(decreasing = TRUE) 
print(best_pred)



```

```{r best predictors}
best_pred <- train_data %>% ungroup() %>%
  dplyr::select(-not_at_home_change,-landkreis,-description ,-year_week,-date,-value,-season) %>%
  map_dbl(cor,y = train_data$not_at_home_change) %>%
  #map_dbl(abs) %>%
  sort(decreasing = TRUE) 
print(best_pred)
```

```{r modelr}


train_data = description_impact %>% left_join(df_holidays, by ="date") %>% replace_na(list(isHoliday = FALSE))



first_model = lm(not_at_home_change ~ ns(tavg,2)+stringency+description+isHoliday+date,
                 data = train_data)
stringency_coef = first_model$coefficients[3]

#train_data = train_data %>% mutate(not_at_home_change = not_at_home_change + stringency_coef*stringency)

second_model = lm(not_at_home_change ~ ns(tavg,1)+date+snow_week+prcp_week+description+isHoliday,
                 data = train_data)

mass_model = MASS::rlm(not_at_home_change ~ ns(tavg,2)+date+stringency+description,
                 data = train_data)
summary(first_model)
```

Need to check auto.arima approach

```{r predictions}
colors = c("actual" = "blue","predicted" = "red","residuals" = "gray50")
model = first_model
test_data = train_data %>% add_predictions(model = model) %>% add_residuals(model = model)

ggplotly(ggplot(test_data) +
  geom_line(aes(x = date,y = not_at_home_change,color = "actual"))+
  geom_line(aes(x = date,y = pred,color = "predicted"))+
  geom_line(aes(x = date,y = resid,color = "residuals"))+
  scale_color_manual(values = colors))

```




```{r}
barplot <- ggplot(test_data, aes(x = resid ))+
  geom_histogram(aes(y = stat(density)),colour="black", fill="white", binwidth=2)+
  geom_density( fill="#FF6666",adjust = 10,alpha = 0.5) 


ggplotly(barplot)
```

```{r residuals verteilung}
fitdistrplus::descdist(test_data$resid)
```

```{r}
normal_dist = fitdistrplus::fitdist(test_data$resid,"norm")
plot(normal_dist)
```
shapiro test p value
```{r}
print(shapiro.test(test_data$resid))
```